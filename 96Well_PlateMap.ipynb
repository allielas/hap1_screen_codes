{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ba80c-8b97-4197-bf9f-8f270eaef611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb110b6-1789-494e-86a5-5f46ed7d7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_namer(row, col):\n",
    "    well_name = str(chr(ord('@')+ row)) + str(col).rjust(2, '0')  #make the number have a left align, adding a zero\n",
    "    return well_name\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_number(string):\n",
    "    match = re.search(r'\\d+', string)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db1be5-2319-48d2-b8f9-b3a923aa1429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 96-well plate CSV file from benchiling/Notion NOTE: don't initialze an empty df, use a list and convert after.\n",
    "\n",
    "plate_path = (\n",
    "    \"plate_metadata/\"  #'/home/mattiazzilab/Documents/Allie_Scripts/May 8 seeding.csv'\n",
    ")\n",
    "\n",
    "export_path = \"plate_metadata/\"  #'/mnt/bigdisk1/Allie_S/Replicative_Age_Project/Data Mining/metadata/'\n",
    "\n",
    "\n",
    "def load_plate_df(path):\n",
    "    raw_plate_df = pd.read_csv(path, header=0, usecols=range(1, 13)).dropna(\n",
    "        axis=1, how=\"all\"\n",
    "    )\n",
    "    plate_df = raw_plate_df.dropna(axis=0, thresh=2)\n",
    "    print(plate_df.shape)  # Checks if correct number of rows and columns\n",
    "\n",
    "    return plate_df\n",
    "\n",
    "\n",
    "def make_map_df(condition_cols, aux_cols):\n",
    "    \"\"\"\n",
    "    Return a df with the required columns\n",
    "    \"\"\"\n",
    "    main_columns = [\n",
    "        \"Metadata_Well\",\n",
    "        \"Metadata_WellRow\",\n",
    "        \"Metadata_WellColumn\",\n",
    "        \"Metadata_Field\",\n",
    "        \"Metadata_RowColFieldCode\",\n",
    "        \"Staining\",\n",
    "    ]\n",
    "    df_cols = main_columns + condition_cols + aux_cols\n",
    "    plate_map_df = pd.DataFrame(columns=df_cols)\n",
    "    print(plate_map_df.columns)\n",
    "    return plate_map_df\n",
    "\n",
    "\n",
    "# plate_df.head(13)\n",
    "# print(columns_row)\n",
    "condition_cols = [\n",
    "    \"SerialPassage_BatchNumber\",\n",
    "    \"AgeGroup\",\n",
    "    \"PassageNumber\",\n",
    "]\n",
    "aux_cols = [\n",
    "    \"Drug\",\n",
    "    \"FlaggedBatch\",\n",
    "    \"TimepointName\",\n",
    "]\n",
    "make_map_df(condition_cols, aux_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d1f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_ops(condition_cols, well_metadata, aux_cols=[]):\n",
    "    updates_dict = {}\n",
    "    text = well_metadata.split(\" \")\n",
    "    # use regex to extract the numerical bits e.g.  grab the number after the B in the serial passage batch\n",
    "    all_cols = condition_cols+aux_cols\n",
    "    for condition in all_cols:\n",
    "        if condition == \"SerialPassage_BatchNumber\":\n",
    "            updates_dict[condition] = text[0].split(\"B\")[1] \n",
    "        elif condition == \"TreatmentGroup\":\n",
    "            updates_dict[condition] = text[0]\n",
    "        elif condition == \"AgeGroup\":\n",
    "            # time used to mean age group - deprecated term but still used in code\n",
    "            updates_dict[condition] = extract_number(text[1])  \n",
    "        elif condition == \"PassageNumber\":\n",
    "            # passage_number(Int(time)) - use the function if you don;t have passage number in the table\n",
    "            updates_dict[condition] = extract_number(text[2]) \n",
    "        elif condition == \"Drug\":\n",
    "            # grab drug, name an\n",
    "            if (\"_\" in text[1]):  \n",
    "                # if there is an underscore than the well is drug-treated for this group\n",
    "                updates_dict[condition] = text[1].split(\"_\")[1]  \n",
    "                # grab the drug name past the underscore\n",
    "            else:\n",
    "                updates_dict[condition] = \"None\"\n",
    "        elif condition == \"FlaggedBatch\":\n",
    "            # flag passage if we have \"Flagged\" in the serial passage batch\n",
    "            updates_dict[condition] = \"Flagged\" in text[0]\n",
    "        elif condition == \"TimepointName\":\n",
    "            updates_dict[condition] = text[0] + \" \" + text[1] + \" \" + text[2]\n",
    "        elif condition == \"ShortStaining\":\n",
    "            new_text = []\n",
    "            for term in text:\n",
    "                term = term.removesuffix(\"INK4A\")\n",
    "                term = term.removesuffix(\"CIP1WAF1\")\n",
    "                if term != \"+\":\n",
    "                    new_text.append(term)\n",
    "            stains = \"_\".join(new_text[len(condition_cols) : len(new_text)])\n",
    "            updates_dict[condition] = stains\n",
    "    return updates_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7614aa4c-8c12-4459-b6da-05c22f6cfa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_platemap_csv(plate_df, plate_name, export_path, condition_cols, aux_cols=[]):\n",
    "    plate_map_df = make_map_df(condition_cols,aux_cols)\n",
    "    columns_row = plate_df.columns  # get_columns_row(plate_df)\n",
    "    for index, data in plate_df.iterrows():\n",
    "        row = data.to_list()\n",
    "        for count, value in enumerate(row):\n",
    "            curr_well = value\n",
    "            if pd.isna(curr_well):\n",
    "                continue\n",
    "            row_list = []\n",
    "            # get string data and label of row in df (e.g. col1, text= R1T0 EAA1-488 Tfn-647)\n",
    "            # regex to separate into different variables\n",
    "            # then add them to dict with their respective col index (label) and index of the row in the column (column.index)\n",
    "            for i in range(40):\n",
    "                row_entry = {}\n",
    "\n",
    "                row_index = index + 1  # Make it 1-indexed\n",
    "\n",
    "                column_index = columns_row[count]  # Use header row for column index\n",
    "                # print(column_index)\n",
    "\n",
    "                if ~np.isnan(row_index):\n",
    "                    well_name = well_namer(row_index, column_index)\n",
    "                else:\n",
    "                    well_name = \"Empty\"\n",
    "                    continue\n",
    "                \n",
    "                # information for the field is just 1-40, nothing else changes\n",
    "                field = i + 1\n",
    "                rowcolfield = f\"r{str(row_index).rjust(2, '0')}c{str(column_index).rjust(2, '0')}f{str(field).rjust(2, '0')}\"\n",
    "                \n",
    "                # seperate well metadata by space\n",
    "                text = curr_well.split(\" \")\n",
    "                \n",
    "                #stains come after all the conditions\n",
    "                n_conditions = len(condition_cols)\n",
    "                stains = \" \".join(\n",
    "                    text[n_conditions : len(text)]\n",
    "                ) \n",
    "                \n",
    "                row_entry.update(\n",
    "                    {\n",
    "                        \"Metadata_Well\": well_name,\n",
    "                        \"Metadata_WellRow\": row_index,\n",
    "                        \"Metadata_WellColumn\": column_index,\n",
    "                        \"Metadata_Field\": field,\n",
    "                        \"Staining\": stains.strip(),\n",
    "                        \"Metadata_RowColFieldCode\":rowcolfield\n",
    "                    }\n",
    "                )\n",
    "                conditional_entries = conditional_ops(condition_cols, curr_well, aux_cols)\n",
    "                row_entry.update(conditional_entries)\n",
    "\n",
    "                row_list.append(row_entry)\n",
    "\n",
    "            rows = pd.DataFrame(row_list)\n",
    "            plate_map_df = pd.concat([plate_map_df, rows], ignore_index=True)\n",
    "            # column_index = column_index+1\n",
    "    plate_map_df.to_csv(os.path.join(export_path, f\"{plate_name}_map.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed2d20-17ac-4892-b4fd-a6a3540d3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for root, dirs, files in os.walk(plate_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".csv\") and \"map\" not in filename and \"Pilot\" not in filename:\n",
    "            file_path = os.path.join(root,filename)\n",
    "            plate_df = load_plate_df(os.path.abspath(file_path))\n",
    "            display(plate_df)\n",
    "            export_path = os.path.abspath(root)\n",
    "            print(f\"Exporting {filename} to {export_path}\")\n",
    "            plate_name = filename.split(\".\")[0]\n",
    "            export_platemap_csv(plate_df, plate_name, export_path, condition_cols, aux_cols=aux_cols)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21fab0-1889-47a4-9627-079d4a755b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the pilot one\n",
    "for root, dirs, files in os.walk(plate_path):\n",
    "    for filename in files:\n",
    "        if (\n",
    "            filename.endswith(\".csv\")\n",
    "            and \"map\" not in filename\n",
    "            and \"Pilot\" in filename\n",
    "        ):\n",
    "            file_path = os.path.join(root, filename)\n",
    "            plate_df = load_plate_df(os.path.abspath(file_path))\n",
    "            display(plate_df)\n",
    "            export_path = os.path.abspath(root)\n",
    "            print(f\"Exporting {filename} to {export_path}\")\n",
    "            plate_name = filename.split(\".\")[0]\n",
    "            \n",
    "            pilot_conditions = [\"TreatmentGroup\"]\n",
    "            pilot_aux = [\"ShortStaining\"]\n",
    "            \n",
    "            export_platemap_csv(\n",
    "                plate_df, plate_name, export_path, condition_cols=pilot_conditions, aux_cols=pilot_aux\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
